{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2014','2015','2016','2017']\n",
    "months = list(range(1,13))\n",
    "time_suffix_lst = []\n",
    "for yr in years:\n",
    "    for month in months:\n",
    "        time_suffix_lst.append(yr+'-'+'%02d'%month)\n",
    "time_suffix_lst_2014 = time_suffix_lst[6:12]\n",
    "time_suffix_lst_new = time_suffix_lst[30:-6]\n",
    "time_suffix_lst = time_suffix_lst[12:30]\n",
    "\n",
    "csv_file_lst_2014 = ['yellow_tripdata_' + time_suffix + '.csv' for time_suffix in time_suffix_lst_2014]\n",
    "csv_path_lst_2014 = [os.path.join('/home/lashi/assets', csv_file) for csv_file in csv_file_lst_2014]\n",
    "csv_file_lst = ['yellow_tripdata_' + time_suffix + '.csv' for time_suffix in time_suffix_lst]\n",
    "csv_path_lst = [os.path.join('/home/lashi/assets', csv_file) for csv_file in csv_file_lst]\n",
    "csv_file_lst_new = ['yellow_tripdata_' + time_suffix + '.csv' for time_suffix in time_suffix_lst_new]\n",
    "csv_path_lst_new = [os.path.join('/home/lashi/assets', csv_file) for csv_file in csv_file_lst_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lashi/assets/sampled_data_2014.pickle\n",
      "796362\n"
     ]
    }
   ],
   "source": [
    "df_pickle = '/home/lashi/assets/sampled_data_2014.pickle'\n",
    "print(df_pickle)\n",
    "df = pd.read_pickle(df_pickle)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting first file: /home/lashi/assets/yellow_tripdata_2014-07.csv\n",
      "Total length: 13106362 Sampled amount: 131063 Reading file...\n",
      "Sampled df length: 131067\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2014-08.csv\n",
      "Total length: 12688874 Sampled amount: 126888 Reading file...\n",
      "Sampled Df length: 126892\n",
      "Saving...\n",
      "Total Df length: 257959\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2014-09.csv\n",
      "Total length: 13374013 Sampled amount: 133740 Reading file...\n",
      "Sampled Df length: 133744\n",
      "Saving...\n",
      "Total Df length: 391703\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2014-10.csv\n",
      "Total length: 14232484 Sampled amount: 142324 Reading file...\n",
      "Sampled Df length: 142328\n",
      "Saving...\n",
      "Total Df length: 534031\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2014-11.csv\n",
      "Total length: 13218213 Sampled amount: 132182 Reading file...\n",
      "Sampled Df length: 132186\n",
      "Saving...\n",
      "Total Df length: 666217\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2014-12.csv\n",
      "Total length: 13014158 Sampled amount: 130141 Reading file...\n",
      "Sampled Df length: 130145\n",
      "Saving...\n",
      "Total Df length: 796362\n"
     ]
    }
   ],
   "source": [
    "# Extract 2014 data\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "PU_dt = ' pickup_datetime'\n",
    "df_pickle = '/home/lashi/assets/sampled_data_2014.pickle'\n",
    "test_40 = '/home/lashi/assets/test_40.csv'\n",
    "\n",
    "\n",
    "csv_path = csv_path_lst_2014[0]\n",
    "print('Counting first file:',csv_path)\n",
    "n = sum(1 for line in open(csv_path)) - 5\n",
    "s = int(n*0.01) # desired sample size\n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "print('Total length:',n,'Sampled amount:',s,'Reading file...')\n",
    "df = pd.read_csv(csv_path,usecols=np.arange(17),parse_dates=[PU_dt],date_parser=dateparse, skiprows=skip)\n",
    "print('Sampled df length:',len(df))\n",
    "\n",
    "for i, csv_path in enumerate(csv_path_lst_2014):\n",
    "    print('------------------------------------------------')\n",
    "    if i != 0:\n",
    "        print('Counting file:',csv_path)\n",
    "        n = sum(1 for line in open(csv_path)) - 5\n",
    "        s = int(n*0.01) # desired sample size\n",
    "        skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "        print('Total length:',n,'Sampled amount:',s,'Reading file...')\n",
    "        df_temp = pd.read_csv(csv_path,usecols=np.arange(17),parse_dates=[PU_dt],date_parser=dateparse, skiprows=skip)\n",
    "        print('Sampled Df length:',len(df_temp))\n",
    "        df = df.append(df_temp)\n",
    "        print('Saving...')\n",
    "        df.to_pickle(df_pickle)\n",
    "        print('Total Df length:',len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting first file: /home/lashi/assets/yellow_tripdata_2015-01.csv\n",
      "Total length: 12748982 Sampled amount: 127489 Reading file...\n",
      "Sampled df length: 127493\n",
      "------------------------------------------------\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-02.csv\n",
      "Total length: 12450517 Sampled amount: 124505 Reading file...\n",
      "Sampled Df length: 124509\n",
      "Saving...\n",
      "Total Df length: 252002\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-03.csv\n",
      "Total length: 13351605 Sampled amount: 133516 Reading file...\n",
      "Sampled Df length: 133520\n",
      "Saving...\n",
      "Total Df length: 385522\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-04.csv\n",
      "Total length: 13071785 Sampled amount: 130717 Reading file...\n",
      "Sampled Df length: 130721\n",
      "Saving...\n",
      "Total Df length: 516243\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-05.csv\n",
      "Total length: 13158258 Sampled amount: 131582 Reading file...\n",
      "Sampled Df length: 131586\n",
      "Saving...\n",
      "Total Df length: 647829\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-06.csv\n",
      "Total length: 12324931 Sampled amount: 123249 Reading file...\n",
      "Sampled Df length: 123253\n",
      "Saving...\n",
      "Total Df length: 771082\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-07.csv\n",
      "Total length: 11562779 Sampled amount: 115627 Reading file...\n",
      "Sampled Df length: 115631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Total Df length: 886713\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-08.csv\n",
      "Total length: 11130300 Sampled amount: 111303 Reading file...\n",
      "Sampled Df length: 111307\n",
      "Saving...\n",
      "Total Df length: 998020\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-09.csv\n",
      "Total length: 11225059 Sampled amount: 112250 Reading file...\n",
      "Sampled Df length: 112254\n",
      "Saving...\n",
      "Total Df length: 1110274\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-10.csv\n",
      "Total length: 12315484 Sampled amount: 123154 Reading file...\n",
      "Sampled Df length: 123158\n",
      "Saving...\n",
      "Total Df length: 1233432\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-11.csv\n",
      "Total length: 11312672 Sampled amount: 113126 Reading file...\n",
      "Sampled Df length: 113130\n",
      "Saving...\n",
      "Total Df length: 1346562\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2015-12.csv\n",
      "Total length: 11460569 Sampled amount: 114605 Reading file...\n",
      "Sampled Df length: 114609\n",
      "Saving...\n",
      "Total Df length: 1461171\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2016-01.csv\n",
      "Total length: 10906854 Sampled amount: 109068 Reading file...\n",
      "Sampled Df length: 109072\n",
      "Saving...\n",
      "Total Df length: 1570243\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2016-02.csv\n",
      "Total length: 11382045 Sampled amount: 113820 Reading file...\n",
      "Sampled Df length: 113824\n",
      "Saving...\n",
      "Total Df length: 1684067\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2016-03.csv\n",
      "Total length: 12210948 Sampled amount: 122109 Reading file...\n",
      "Sampled Df length: 122113\n",
      "Saving...\n",
      "Total Df length: 1806180\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2016-04.csv\n",
      "Total length: 11934334 Sampled amount: 119343 Reading file...\n",
      "Sampled Df length: 119347\n",
      "Saving...\n",
      "Total Df length: 1925527\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2016-05.csv\n",
      "Total length: 11836849 Sampled amount: 118368 Reading file...\n",
      "Sampled Df length: 118372\n",
      "Saving...\n",
      "Total Df length: 2043899\n",
      "------------------------------------------------\n",
      "Counting file: /home/lashi/assets/yellow_tripdata_2016-06.csv\n",
      "Total length: 11135466 Sampled amount: 111354 Reading file...\n",
      "Sampled Df length: 111358\n",
      "Saving...\n",
      "Total Df length: 2155257\n"
     ]
    }
   ],
   "source": [
    "# Extract post-2014 data\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "PU_dt = 'tpep_pickup_datetime'\n",
    "df_pickle = '/home/lashi/assets/sampled_data_2015_2016.pickle'\n",
    "\n",
    "csv_path = csv_path_lst[0]\n",
    "print('Counting first file:',csv_path)\n",
    "n = sum(1 for line in open(csv_path)) - 5\n",
    "s = int(n*0.01) # desired sample size\n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "print('Total length:',n,'Sampled amount:',s,'Reading file...')\n",
    "df = pd.read_csv(csv_path,usecols=np.arange(17),parse_dates=[PU_dt],date_parser=dateparse, skiprows=skip)\n",
    "print('Sampled df length:',len(df))\n",
    "\n",
    "for i, csv_path in enumerate(csv_path_lst):\n",
    "    print('------------------------------------------------')\n",
    "    if i != 0:\n",
    "        print('Counting file:',csv_path)\n",
    "        n = sum(1 for line in open(csv_path)) - 5\n",
    "        s = int(n*0.01) # desired sample size\n",
    "        skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "        print('Total length:',n,'Sampled amount:',s,'Reading file...')\n",
    "        df_temp = pd.read_csv(csv_path,usecols=np.arange(17),parse_dates=[PU_dt],date_parser=dateparse, skiprows=skip)\n",
    "        print('Sampled Df length:',len(df_temp))\n",
    "        df = df.append(df_temp)\n",
    "        print('Saving...')\n",
    "        df.to_pickle(df_pickle)\n",
    "        print('Total Df length:',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract post-2016 data\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "PU_dt = 'tpep_pickup_datetime'\n",
    "df_pickle = '/home/lashi/assets/sampled_data_post2016.pickle'\n",
    "\n",
    "csv_path = csv_path_lst[0]\n",
    "print('Counting first file:',csv_path)\n",
    "n = sum(1 for line in open(csv_path)) - 5\n",
    "s = int(n*0.01) # desired sample size\n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "print('Total length:',n,'Sampled amount:',s,'Reading file...')\n",
    "df = pd.read_csv(csv_path,usecols=np.arange(17),parse_dates=[PU_dt],date_parser=dateparse, skiprows=skip)\n",
    "print('Sampled df length:',len(df))\n",
    "\n",
    "for i, csv_path in enumerate(csv_path_lst):\n",
    "    print('------------------------------------------------')\n",
    "    if i != 0:\n",
    "        print('Counting file:',csv_path)\n",
    "        n = sum(1 for line in open(csv_path)) - 5\n",
    "        s = int(n*0.01) # desired sample size\n",
    "        skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "        print('Total length:',n,'Sampled amount:',s,'Reading file...')\n",
    "        df_temp = pd.read_csv(csv_path,usecols=np.arange(17),parse_dates=[PU_dt],date_parser=dateparse, skiprows=skip)\n",
    "        print('Sampled Df length:',len(df_temp))\n",
    "        df = df.append(df_temp)\n",
    "        print('Saving...')\n",
    "        df.to_pickle(df_pickle)\n",
    "        print('Total Df length:',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lashi/assets/sampled_data_2015_2016.pickle\n",
      "2155257\n"
     ]
    }
   ],
   "source": [
    "df_pickle = '/home/lashi/assets/sampled_data_2015_2016.pickle'\n",
    "print(df_pickle)\n",
    "df = pd.read_pickle(df_pickle)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RateCodeID', 'RatecodeID', 'VendorID', 'dropoff_latitude',\n",
      "       'dropoff_longitude', 'extra', 'fare_amount', 'mta_tax',\n",
      "       'passenger_count', 'payment_type', 'pickup_latitude',\n",
      "       'pickup_longitude', 'store_and_fwd_flag', 'tip_amount', 'tolls_amount',\n",
      "       'tpep_dropoff_datetime', 'tpep_pickup_datetime', 'trip_distance'],\n",
      "      dtype='object')\n",
      "1386190 -73.97210693359375\n",
      "1386191 -73.99016571044923\n",
      "1386192 -74.00225067138672\n",
      "1386193 -73.98851776123048\n",
      "1386194 -73.99172973632812\n",
      "1386195 -73.1500244140625\n",
      "1386196 -73.97698974609375\n",
      "1386197 -73.977294921875\n",
      "1386198 -73.96381378173827\n",
      "1386199 -73.8202133178711\n"
     ]
    }
   ],
   "source": [
    "test = df['dropoff_longitude']\n",
    "print(df.keys())\n",
    "for i in range(1386190,1386200):\n",
    "    print(i,test.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['dropoff_longitude'].iloc[1386195] = -73.1500244140625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickle = '/home/lashi/assets/sampled_data_2015_2016.pickle'\n",
    "df.to_pickle(df_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBuckets = createTimeBuckets(30)\n",
    "def createTimeBuckets(slot):\n",
    "    # loop to create time bucket dictionary\n",
    "    time_buckets = dict()\n",
    "    numBuckets = int(24*(60/slot))\n",
    "    ind = 0\n",
    "    for hr in range(24):\n",
    "        for i in range(int(60/slot)):\n",
    "            key = '%02d'%hr+':'+'%02d'%(i*slot)+':00'\n",
    "            oneHotVec = np.zeros((1,numBuckets)).astype('int')\n",
    "            oneHotVec[0,ind] = 1\n",
    "            time_buckets[key] = ind\n",
    "            time_buckets[ind] = oneHotVec\n",
    "            ind += 1\n",
    "\n",
    "    return time_buckets\n",
    "    \n",
    "def parsetime(data_frame, desired_labels, dt_label):\n",
    "    data_frame[dt_label] = pd.to_datetime(data_frame[dt_label])\n",
    "    data_frame[dt_label] = data_frame[dt_label].dt.round('30min')\n",
    "    data_frame[desired_labels[1]] = data_frame[dt_label].dt.dayofweek\n",
    "    data_frame[desired_labels[2]] = data_frame[dt_label].dt.time.apply(lambda x: self.timeBuckets[str(x)])\n",
    "    data_frame[desired_labels[3]] = data_frame[dt_label].dt.month\n",
    "\n",
    "    return data_frame.groupby(desired_labels).size().reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
