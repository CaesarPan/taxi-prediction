{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_percentage = .05\n",
    "df = pd.read_pickle('./assets/clean-data/full_data_161718_bucketed.pickle')\n",
    "dataset_size = len(df)\n",
    "\n",
    "print(df.keys())\n",
    "\n",
    "df = df[['PULocationID', 'DOLocationID', 'day_of_week', 't_bucket',\n",
    "              'month', 'cluster_id', 'fare_bucket', 'dist_bucket']]\n",
    "\n",
    "print(df.keys())\n",
    "df = df.drop(['month'], axis=1)\n",
    "\n",
    "train = joblib.load('train-fare.joblib')\n",
    "valid = joblib.load('valid-fare.joblib')\n",
    "\n",
    "# train, valid = train_test_split(df, test_size=0.05)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=40, n_jobs=-1, verbose=3, criterion='entropy')\n",
    "\n",
    "xTrain = train.drop(['DOLocationID', 'dist_bucket', 'fare_bucket'], axis=1)\n",
    "yTrain = train['fare_bucket']\n",
    "\n",
    "classifier.fit(xTrain, yTrain)\n",
    "\n",
    "joblib.dump(classifier, './rf-models/rf-fare-lid-wclus-entropy.joblib')\n",
    "# joblib.dump(train, 'train-fare-wcluster.joblib')\n",
    "# joblib.dump(valid, 'valid-fare-wcluster.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load('./rf-models/rf-fare-lid-wclus-entropy.joblib')\n",
    "valid = joblib.load('valid-fare.joblib')\n",
    "\n",
    "xTest = valid.drop(['DOLocationID', 'dist_bucket', 'fare_bucket'], axis=1)\n",
    "yTest = valid['fare_bucket']\n",
    "\n",
    "predictions = classifier.predict(xTest)\n",
    "\n",
    "# valid['predictions'] = predictions\n",
    "# valid.to_pickle('./assets/predictions_fare.pickle')\n",
    "\n",
    "print(np.mean(yTest == predictions))\n",
    "print(classifier.feature_importances_)\n",
    "print(xTest.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_percentage = .05\n",
    "df = pd.read_pickle('./assets/data_set_master.pickle')\n",
    "dataset_size = len(df)\n",
    "\n",
    "df = df.drop(['month'], axis=1)\n",
    "\n",
    "train, valid = train_test_split(df, test_size=0.05)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=40, n_jobs=-1, verbose=3)\n",
    "\n",
    "xTrain = train.drop(['fare_amount', 'trip_distance', 'fare_bucket', 'dist_bucket'], axis=1)\n",
    "yTrain = train['dist_bucket']\n",
    "\n",
    "classifier.fit(xTrain, yTrain)\n",
    "\n",
    "joblib.dump(classifier, 'rf_dist.joblib')\n",
    "joblib.dump(train, 'train_dist.joblib')\n",
    "joblib.dump(valid, 'valid_dist.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('rf_dist.joblib')\n",
    "valid = joblib.load('valid_fare.joblib')\n",
    "\n",
    "xTest = valid.drop(['fare_amount', 'trip_distance', 'fare_bucket', 'dist_bucket'], axis=1)\n",
    "yTest = valid['dist_bucket']\n",
    "\n",
    "predictions = clf.predict(xTest)\n",
    "\n",
    "print(np.mean(yTest == predictions))\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_percentage = .05\n",
    "df = pd.read_pickle('./assets/activity_master.pickle')\n",
    "dataset_size = len(df)\n",
    "\n",
    "print(df.head())\n",
    "train, valid = train_test_split(df, test_size=0.05)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=40, n_jobs=-1, verbose=3)\n",
    "\n",
    "xTrain = train.drop(['activity', 'activity_bucket'], axis=1)\n",
    "yTrain = train['activity_bucket']\n",
    "\n",
    "classifier.fit(xTrain, yTrain)\n",
    "\n",
    "joblib.dump(classifier, 'rf_act.joblib')\n",
    "joblib.dump(train, 'train_act.joblib')\n",
    "joblib.dump(valid, 'valid_act.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('rf_act.joblib')\n",
    "valid = joblib.load('valid_act.joblib')\n",
    "\n",
    "xTest = valid.drop(['activity', 'activity_bucket'], axis=1)\n",
    "yTest = valid['activity_bucket']\n",
    "\n",
    "predictions = clf.predict(xTest)\n",
    "\n",
    "valid['predictions'] = predictions\n",
    "valid.to_pickle('./assets/activity_predictions.pickle')\n",
    "\n",
    "print(np.mean(yTest == predictions))\n",
    "print(clf.feature_importances_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
