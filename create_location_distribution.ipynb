{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pickle = '/home/lashi/assets/clean-data/full_data_141516.pickle'\n",
    "df = pd.read_pickle(df_pickle).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time buckets (only needs to be run once)\n",
    "def createTimeBuckets(slot):\n",
    "    # loop to create time bucket dictionary\n",
    "    time_buckets = dict()\n",
    "    numBuckets = int(24*(60/slot))\n",
    "    ind = 0\n",
    "    for hr in range(24):\n",
    "        for i in range(int(60/slot)):\n",
    "            key = '%02d'%hr+':'+'%02d'%(i*slot)+':00'\n",
    "            oneHotVec = np.zeros((1,numBuckets)).astype('int')\n",
    "            oneHotVec[0,ind] = 1\n",
    "            time_buckets[key] = ind\n",
    "            time_buckets[ind] = oneHotVec\n",
    "            ind += 1\n",
    "\n",
    "    return time_buckets\n",
    "    \n",
    "def parsetime(data_frame, desired_labels, dt_label, timeBuckets):\n",
    "    data_frame[dt_label] = pd.to_datetime(data_frame[dt_label])\n",
    "    data_frame[dt_label] = data_frame[dt_label].dt.round('30min')\n",
    "    data_frame[desired_labels[0]] = data_frame[dt_label].dt.dayofweek\n",
    "    data_frame[desired_labels[1]] = data_frame[dt_label].dt.time.apply(lambda x: timeBuckets[str(x)])\n",
    "    data_frame[desired_labels[2]] = data_frame[dt_label].dt.month\n",
    "\n",
    "tBuckets = createTimeBuckets(30)\n",
    "desired_labels = ['day_of_week','t_bucket','month']\n",
    "PU_dt = 'tpep_pickup_datetime'\n",
    "parsetime(df,desired_labels,PU_dt,tBuckets)\n",
    "# df.to_pickle(df_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05319149 0.15957447 0.08510638 0.15957447 0.08510638 0.06382979\n",
      " 0.08510638 0.07446809 0.20212766 0.03191489]\n"
     ]
    }
   ],
   "source": [
    "df_cluster_ids = df.groupby(['pickup_id','cluster_id']).size().reset_index()\n",
    "df_pickup_ids = df.groupby(['pickup_id']).size().reset_index()\n",
    "cluster_dist_dict = dict()\n",
    "\n",
    "for i in range(len(df_pickup_ids)):\n",
    "    pickup_id = df_pickup_ids['pickup_id'][i]\n",
    "    id_set = df_cluster_ids.loc[df_cluster_ids['pickup_id']==pickup_id].reset_index()\n",
    "    num_clusters = len(id_set)\n",
    "    cluster_dist = np.zeros(num_clusters)\n",
    "    for cluster in range(num_clusters):\n",
    "        cluster_dist[cluster] = id_set[0].loc[cluster]\n",
    "    cluster_dist = cluster_dist/np.sum(cluster_dist)\n",
    "    cluster_dist_dict[pickup_id] = cluster_dist\n",
    "    \n",
    "print(cluster_dist_dict[85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2['pickup_id'][255])\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
